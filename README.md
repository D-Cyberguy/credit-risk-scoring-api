Credit Risk Scoring API
A production-ready Machine Learning inference service built with FastAPI + Docker, serving a trained Gradient Boosting credit risk model for real-time and batch loan application scoring.
This project demonstrates end-to-end ML serving engineering, not just modeling.

It includes:


strict schema validation


deterministic preprocessing


model inference


business decision logic


request tracing


structured logging


lightweight metrics


Dockerized deployment


automated tests



ğŸš€ Features
Prediction


Single scoring (/predict)


Batch scoring (/predict/batch, up to 500)


Explainability with SHAP (/predict/explain)


Observability


Request IDs


Structured JSON logs


Latency tracking


In-memory metrics endpoint


Health checks


Engineering


Clean service architecture


Model artifact separation


Pytest tests


Dockerized runtime


Cloud deployment ready



ğŸ§  Architecture
Client Request
      â†“
FastAPI Validation
      â†“
Preprocessing (cleaning + feature engineering)
      â†“
Schema Enforcement
      â†“
Model Inference
      â†“
Business Decision Logic
      â†“
Response + Logging + Metrics

Key principle:

Model predicts risk
Business layer makes decisions


ğŸ“¦ Project Structure
credit_risk_api/
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                 # FastAPI entrypoint + middleware + routes
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ preprocessing.py
â”‚       â”œâ”€â”€ inference.py
â”‚       â”œâ”€â”€ explainability.py
â”‚       â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ cleaning.py
â”‚   â””â”€â”€ features.py
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ gradient_boosting_model.joblib
â”‚       â”œâ”€â”€ feature_schema.json
â”‚       â”œâ”€â”€ decision_threshold.json
â”‚       â””â”€â”€ model_metadata.json
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore


ğŸ§ª API Endpoints
Health
GET /health

{ "status": "ok" }


Version
GET /version

{
  "service": "credit-risk-api",
  "model_version": "v1.0.0"
}


Single Prediction
POST /predict

Returns:
{
  "decision": "APPROVE",
  "prediction": 0,
  "probability_of_default": 0.049
}


Batch Prediction
POST /predict/batch

Vectorized scoring for multiple records.

Metrics
GET /metrics

Returns:


total requests


latency


decision counts


batch vs single counts




ğŸ“Š Logging (Structured)
All requests generate JSON logs:
Example:
{
  "timestamp": "2026-02-04T12:09:51Z",
  "level": "INFO",
  "message": "request_id=abc123 method=POST path=/predict duration_ms=42.3"
}

Each prediction logs:
request_id, probability, decision

Useful for:


monitoring


debugging


tracing


production observability




ğŸ§ª Running Tests (Docker)
We test inside the same runtime as production:
docker build -t credit-risk-api .
docker run --rm credit-risk-api pytest -v

Example:
2 passed in 3.0s



âš™ï¸ Run Locally (No Docker)
python -m venv .venv # python version depends on you
source .venv/bin/activate
pip install -r requirements.txt
uvicorn api.main:app --reload

Docs:
http://127.0.0.1:8000/docs



ğŸ³ Run With Docker
Build:
docker build -t credit-risk-api .

Run:
docker run -p 8000:8000 credit-risk-api



ğŸ³ Docker Compose
docker compose up -d

Includes:


API


healthcheck


restart policy




â˜ï¸ Deployment Ready
Designed for:


AWS ECS / Fargate


Google Cloud Run


Azure Container Apps


Kubernetes


Containerized = same behavior everywhere.


WHICH EVER OF THE ABOVE WORKS FOR YOU!